{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e996f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based off of the 'Build a Generative Adversarial Neural Network' tutorial by Nicholas Renotte\n",
    "# Tutorial Video Link: 'https://www.youtube.com/watch?v=AALBGpLbj6Q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a128bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Dependencies\n",
    "#!pip3 install ipywidgets\n",
    "#!pip3 install matplotlib\n",
    "#!pip3 install tensorflow\n",
    "#!pip3 install tensorflow-datasets\n",
    "#!pip3 install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42846527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Available & Installed PIP Packages\n",
    "#!pip3 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af64cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Importing the base model class to subclass the training step\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Fashion Dataset\n",
    "\n",
    "# Utilizing the TensorFlow Datasets API so as to bring in the data source\n",
    "fashion_ds = tfds.load('fashion_mnist', split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66738fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fashion_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c248d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Is a classification dataset, with an image being associated with some form of clothing\n",
    "    such as shirts, pants, boots, shoes, etc.\n",
    "Think of the code below as using a pipeline, with a set of repeatable calls used in order\n",
    "    to bring in the fashion data back via the TensorFlow Dataset API\n",
    "An iterator, similar to a loop, keeps having batches of images called up one after the other\n",
    "    with '.next()'\n",
    "''' \n",
    "fashion_ds.as_numpy_iterator().next().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing The Dataset\n",
    "\n",
    "# Setting up an iterator and data connection\n",
    "data_iterator = fashion_ds.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8720b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Going to the next image via the previously established iterator\n",
    "Each time the below command is run a new image and its associated data is fetched\n",
    "Helps preserve the available amount of local memory upon the current computer by calling\n",
    "    and fetching the data as needed, rather than loading everything all at once into memory\n",
    "Data is being retrieved from a pipeline\n",
    "'''\n",
    "data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8181b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Setting up the subplots formatting, with a total of 4 columns \n",
    "    and each plots size being 20 by 20 pixels in size\n",
    "The whole display is 'figure', whilst each individual subplot is represent by 'subplot'\n",
    "'''\n",
    "figure, subplot = plt.subplots(ncols = 4, figsize = (20, 20))\n",
    "\n",
    "# Displaying 4 images from the fashion dataset as examples\n",
    "for index in range(4):\n",
    "    \n",
    "    # Grabs an image along with its associated label\n",
    "    batch = data_iterator.next()\n",
    "    \n",
    "    '''\n",
    "    Plots the image for visual display utilizing a specific subplot\n",
    "    Original image arrays 'squeezed' down from 3 to 2 dimensions for easier\n",
    "        visualization, and so some minor data transformation has occured\n",
    "    '''\n",
    "    subplot[index].imshow(np.squeeze(batch['image']))\n",
    "    \n",
    "    # Appens the image label as the specific subplot's associated title\n",
    "    subplot[index].title.set_text(batch['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Even squeezed down, the images are represented from values of 0 to 255, \n",
    "    for neural networks and other good deep learning models these should\n",
    "    be scaled down to become values of either 0 or 1\n",
    "'''\n",
    "\n",
    "# Scales own and returns the images only, without their associated labels\n",
    "def scale_images(data):\n",
    "    image = data['image']\n",
    "    return (image / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed588d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Building The Dataset\n",
    "\n",
    "Typical steps for building up a TensorFlow Pipeline:\n",
    "    1. Map\n",
    "    2. Cache\n",
    "    3. Shuffle\n",
    "    4. Batch\n",
    "    5. Prefetch\n",
    "'''\n",
    "\n",
    "# Reloads the dataset if not already done\n",
    "#fashion_ds = tfds.load('fashion_mnist', split = 'train')\n",
    "\n",
    "# Running the dataset through the 'scale_images' function preprocessing step\n",
    "fashion_ds = fashion_ds.map(scale_images)\n",
    "\n",
    "# Caching the dataset for the given batch\n",
    "fashion_ds = fashion_ds.cache()\n",
    "\n",
    "'''\n",
    "Shuffles the dataset similarly to shuffling a deck of cards to avoid repeatedly\n",
    "    looking at the same set of data every time and therefore making erroneus conclusions\n",
    "'''\n",
    "fashion_ds = fashion_ds.shuffle(60000)\n",
    "\n",
    "# Batches of 128 images are gathered per sample\n",
    "fashion_ds = fashion_ds.batch(128)\n",
    "\n",
    "# Reduces the likelihood of bottlenecking during the process\n",
    "fashion_ds = fashion_ds.prefetch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a970d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The iterator should retrieve a batch of 128 images all of dimensions 28 by 28 pixels \n",
    "    by 1 channel, signaling their being grayscale in nature\n",
    "'''\n",
    "fashion_ds.as_numpy_iterator().next().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building The Neural Network\n",
    "\n",
    "# Building The Synthetic Data Generator\n",
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    \n",
    "    '''\n",
    "    Specifies what the input layer is going to be\n",
    "    Dense, fully connected layer, with 128 random values being passed in in order\n",
    "        to help the generator decide what to create in terms of 7 by 7 pixel sized \n",
    "        images by giving it some latent space context\n",
    "    '''\n",
    "    model.add(Dense(7 * 7 * 128, input_dim = 128))\n",
    "    \n",
    "    # Leaky ReLU activation, recommended in data synthesis and generation neural networks\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    '''\n",
    "    Reshaping the dense layer's output into the begginings of an image, which at this point\n",
    "        is 7 by 7 pixels with 128 different channels\n",
    "    '''\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    \n",
    "    '''\n",
    "    Upsampling blocks are meant to push the newly generated beginnings of \n",
    "        images closer to what the desired output should actually be in terms of pixel\n",
    "        size and channels\n",
    "    '''\n",
    "    \n",
    "    # Upsampling Block 1\n",
    "    \n",
    "    '''\n",
    "    Reshapes the generated model images by upsampling them to 14 by 14 pixel \n",
    "        images with 128 layers, in this case likely simply duplicating pixels\n",
    "        side by side to generate a large image\n",
    "    '''\n",
    "    model.add(UpSampling2D())\n",
    "    \n",
    "    '''\n",
    "    Convolutional layer condenses this upsampled output back down, removing the upsampling\n",
    "        paramater data to limit the amount of information\n",
    "    Padding avoids undesired image cropping within this scenario\n",
    "    '''\n",
    "    model.add(Conv2D(128, 5, padding = 'same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Upsampling Block 2\n",
    "    # Images become 28 by 28 pixels with 128 layers\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 5, padding = 'same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    '''\n",
    "    Convolutional blocks made in order to provide more paramaters for the model to \n",
    "        play around with when generating synthetic images as data\n",
    "    '''\n",
    "    \n",
    "    # Convolutional Block 1\n",
    "    model.add(Conv2D(128, 4, padding = 'same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Convolutional Block 2\n",
    "    model.add(Conv2D(128, 4, padding = 'same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Convolutional layers to reach an image with only 1 channel\n",
    "    model.add(Conv2D(1, 4, padding = 'same', activation = 'sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d1d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 4 synthetic images\n",
    "test_image = generator.predict(np.random.randn(4, 128, 1))\n",
    "\n",
    "# Visualizing newly generated synthetic images data from the generator\n",
    "figure, subplot = plt.subplots(ncols = 4, figsize = (20, 20))\n",
    "for index, image in enumerate(test_image):\n",
    "    subplot[index].imshow(np.squeeze(image))\n",
    "    subplot[index].title.set_text(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce155ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1eb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building The Discriminator\n",
    "\n",
    "# Essential acts as an image classifier\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolutional Block 1\n",
    "    '''\n",
    "    Convolutional layer has 32 filters with a shape of 5 by 5\n",
    "    Input shape is that of a proper desired fashion image\n",
    "    '''\n",
    "    model.add(Conv2D(32, 5, input_shape = (28, 28, 1)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Convolutional Block 2\n",
    "    model.add(Conv2D(64, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Convolutional Block 3\n",
    "    model.add(Conv2D(128, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Convolutional Block 4\n",
    "    model.add(Conv2D(256, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Flattens and passes into a dense layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    '''\n",
    "    An output value of '1' represents a False, synthesized and generated image,\n",
    "        whilst a '0' represents a True, meaning the image comes from a real life\n",
    "        piece of clothing\n",
    "    '''\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f61583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6480765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts whether or not the synthesized and generated test images are real or fake\n",
    "discriminator.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Constructing The Training Loop\n",
    "\n",
    "Generators have to train the generator and discriminator side by side in order to \n",
    "    properly learn, and so simply using the typical '.fit()' function does not \n",
    "    work in this scenario\n",
    "A specific training sequence, or loop, is therefore needed for these types of neural networks\n",
    "'''\n",
    "\n",
    "'''\n",
    "Setting Up Losses & Optimizers\n",
    "\n",
    "The generator model will be rewarded for tricking the discriminator, whilst the \n",
    "    discriminator will be rewarded for sniffing out the generator's bogus fashion\n",
    "    items\n",
    "The learning rate for the discriminator will be slower than the generator in order to prevent\n",
    "    the former discriminator from completely crushing the generator before the latter has time to\n",
    "    properly learn to make convincing synthetic data\n",
    "'''\n",
    "\n",
    "generator_optimizer = Adam(learning_rate = 0.0001)\n",
    "discriminator_optimizer = Adam(learning_rate = 0.00001)\n",
    "\n",
    "generator_loss = BinaryCrossentropy()\n",
    "discriminator_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e225487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Up The Subclassed Model\n",
    "\n",
    "class FashionGAN(Model):\n",
    "    \n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        \n",
    "        # Passes through the positional and keyword arguments into the base Model class\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Creates attributes for the generator and discriminator respectively\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "    \n",
    "    def compile(self, generator_optimizer, discriminator_optimizer, generator_loss, discriminator_loss,\n",
    "                *args, **kwargs):\n",
    "        \n",
    "        # Compiles with the base Model class\n",
    "        super().compile(*args, **kwargs)\n",
    "        \n",
    "        # Creates attributes for the generator's and discriminator's optimizers and losses\n",
    "        self.generator_optimizer = generator_optimizer\n",
    "        self.discriminator_optimizer = discriminator_optimizer\n",
    "        \n",
    "        self.generator_loss = generator_loss\n",
    "        self.discriminator_loss = discriminator_loss\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        \n",
    "        # Retrives the data\n",
    "        real_images = batch\n",
    "        fake_images = self.generator(tf.random.normal((128, 128, 1)), training = False)\n",
    "        \n",
    "        # Trains the discriminator\n",
    "        with tf.GradientTape() as discriminator_tape:\n",
    "            \n",
    "            #Passes in the real and fake images to the discriminator model\n",
    "            yhat_real = self.discriminator(real_images, training = True)\n",
    "            yhat_fake = self.discriminator(fake_images, training = True)\n",
    "            \n",
    "            # Predicitions from the discriminator\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis = 0)\n",
    "            \n",
    "            # Creates labels for both the respective real and fake images, actual results\n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis = 0)\n",
    "            \n",
    "            # Adds some noise to the outputs to prevent the discriminator from learning too quickly\n",
    "            noise_real = 0.15 * tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake = -0.15 * tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += 0.15 * tf.concat([noise_real, noise_fake], axis = 0)\n",
    "            \n",
    "            # Calculates the training loss\n",
    "            total_discriminator_loss = self.discriminator_loss(y_realfake, yhat_realfake)\n",
    "            \n",
    "        # Applies backpropogation, which effectively allows for the neural network to learn\n",
    "        discriminator_gradient = discriminator_tape.gradient(total_discriminator_loss, \n",
    "                                                             self.discriminator.trainable_variables)\n",
    "        \n",
    "        self.discriminator_optimizer.apply_gradients(zip(discriminator_gradient, \n",
    "                                                         self.discriminator.trainable_variables))\n",
    "        \n",
    "        # Trains the generator\n",
    "        with tf.GradientTape() as generator_tape:\n",
    "\n",
    "            # Generates new imahes\n",
    "            generated_images = self.generator(tf.random.normal((128, 128, 1)), training = True)\n",
    "\n",
    "            # Creates the predicted labels\n",
    "            predicted_labels = self.discriminator(generated_images, training = False)\n",
    "            \n",
    "            '''\n",
    "            Calculates loss\n",
    "            The generator attemps to trick the discriminator by labeling its synthesized clothing\n",
    "                images as true, and will be rewarded if it does so successfully, whilst labeling\n",
    "                the real images as false\n",
    "            '''\n",
    "            total_generator_loss = self.generator_loss(tf.zeros_like(predicted_labels), predicted_labels)\n",
    "            \n",
    "        # Applies backpropogation\n",
    "        generator_gradient = generator_tape.gradient(total_generator_loss,\n",
    "                                                     self.generator.trainable_variables)\n",
    "        \n",
    "        self.generator_optimizer.apply_gradients(zip(generator_gradient, \n",
    "                                                     self.generator.trainable_variables))\n",
    "        \n",
    "        return {\"discriminator_loss\":total_discriminator_loss, \"generator_loss\":total_generator_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an instance of the subclassed model\n",
    "fashion_gan = FashionGAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles the instantiated model\n",
    "fashion_gan.compile(generator_optimizer, discriminator_optimizer, generator_loss, discriminator_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a147bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Callback\n",
    "class ModelMonitor(Callback):\n",
    "    \n",
    "    def __init__(self, number_of_images = 3, latent_dim = 128):\n",
    "        self.number_of_images = number_of_images\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        random_latent_vectors = tf.random.uniform((self.number_of_images, self.latent_dim, 1))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        \n",
    "        for index in range(self.number_of_images):\n",
    "            image = array_to_img(generated_images[index])\n",
    "            image.save(os.path.join('GANImages', f'generated_img_{epoch}_{index}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4bc13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Models\n",
    "\n",
    "# 2000 Epochs Recommended\n",
    "history = fashion_gan.fit(fashion_ds, epochs = 20, callbacks = [ModelMonitor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Model Performances\n",
    "plt.suptitle('Loss')\n",
    "plt.plot(hist.history['discriminator_loss'], label = 'Discriminator Loss')\n",
    "plt.plot(hist.history['generator_loss'], label = 'Generator Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ed872",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights(os.path.join('Models', 'generatormodel.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Out The Generator\n",
    "generated_images = generator.predict(tf.random.normal((16, 128, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8129031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the generated synthetic images from a trained generator model\n",
    "figure, subplot = plt.subplots(ncols = 4, nrows = 4, figsize = (20, 20))\n",
    "\n",
    "for row in range(4):\n",
    "    for column in range(4)\n",
    "        subplot[row][column].imshow(generated_images[(row + 1) * (column + 1) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd47aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving The Model\n",
    "generator.save('generator.h5')\n",
    "discriminator.save('discriminator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
